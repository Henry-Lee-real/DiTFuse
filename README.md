# MaeFuse
Official implementation of **Towards Unified Semantic and Controllable Image Fusion: A Diffusion Transformer Approach** (TPAMI 2025)

paper and all detail information will be release before 12.7
Any questions can be consulted -> (Email:lijiayang.cs@gmail.com)

### ğŸ“Œ TODOs
> - [ ] release code  
> - [X] release ckpt
> - [ ] release arxiv
> - [ ] IEEE version paper



## ğŸš€ Overview

[![HuggingFace](https://img.shields.io/badge/HuggingFace-DiTFuse-ffcc4d?logo=huggingface&logoColor=white&style=flat)](https://huggingface.co/lijiayangCS/DiTFuse)

[![Project Page](https://img.shields.io/badge/ğŸŒâ€“Project%20Pageâ€“blue?logo=github&logoColor=white&style=flat)](https://ronniejiang.github.io/DiTFuse/)




## ğŸ§© Environment Setup

DiTFuse is developed entirely on top of **OmniGen**.
Please install the OmniGen environment **before** running DiTFuse.

ğŸ‘‰ **Follow the official OmniGen setup guide:**
[https://github.com/VectorSpaceLab/OmniGen](https://github.com/VectorSpaceLab/OmniGen)

After configuring the OmniGen environment, DiTFuse scripts can be run directly.



## ğŸ“¦ Model Weights

DiTFuse requires two components:

### **1ï¸âƒ£ Base Model (Required)**

We use OmniGen-v1 as the foundational diffusion transformer:

ğŸ‘‰ **OmniGen-v1:**
[https://huggingface.co/Shitao/OmniGen-v1](https://huggingface.co/Shitao/OmniGen-v1)



### **2ï¸âƒ£ DiTFuse Fine-tuned Weights (LoRA)**

Our semantic-aware and instruction-controllable LoRA modules:

ğŸ‘‰ **DiTFuse LoRA Weights:**
[https://huggingface.co/lijiayangCS/DiTFuse](https://huggingface.co/lijiayangCS/DiTFuse)

These LoRA weights must be merged into the OmniGen base model before inference.



## ğŸ“ Project Structure (Preview)

```
DiTFuse/
â”‚â”€â”€ scripts/
â”‚   â”œâ”€â”€ run_single.py
â”‚   â”œâ”€â”€ run_batch.py
â”‚   â”œâ”€â”€ run_prompt.py
â”‚â”€â”€ configs/
â”‚â”€â”€ checkpoints/
â”‚â”€â”€ README.md
```


## â–¶ï¸ Quick Start (Example)

### **Single Pair Fusion**

```bash
python run.py \
  --mode single \
  --image1 path/to/img1.png \
  --image2 path/to/img2.png \
  --prompt_single "Fuse the two images while preserving thermal targets."
```

### **Batch Fusion**

```bash
python run.py \
  --mode batch \
  --image_dir ./data/fusion_pairs \
  --prompt_batch "High-clarity multispectral fusion."
```

### **Prompt Library Fusion**

```bash
python run.py \
  --mode prompt \
  --prompt_file prompts.txt \
  --image1 img_a.png \
  --image2 img_b.png
```



## ğŸ“„ Citation

If you use **DiTFuse** in your research, please cite:

```
@article{ditfuse2025,
  title={Towards Unified Semantic and Controllable Image Fusion: A Diffusion Transformer Approach},
  author={Jiayang Li, Chengjie Jiang, Pengwei Liang, Jiayi Ma, Liqiang Nie, Junjun Jiang},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year={2025}
}
```



## â¤ï¸ Acknowledgements

This project is built on top of **OmniGen**,
a powerful Diffusion Transformer framework developed by VectorSpace Lab.

---

